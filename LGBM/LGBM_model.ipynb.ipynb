{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Library & Seed Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import requests\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import re\n",
    "import math\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from hyperopt.pyll import scope\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams['font.family'] = 'NanumGothic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_setting(seed=1004) :\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1406/2365525185.py:3: DtypeWarning: Columns (16,17,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv(\"train.csv\")\n"
     ]
    }
   ],
   "source": [
    "bus_data = pd.read_csv(\"bus_feature.csv\")\n",
    "subway_data = pd.read_csv(\"subway_feature.csv\")\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "apart_data = pd.read_csv('Apart_data.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entire_Preprocessing(df) :\n",
    "    # 문자열 컬럼만 찾아서 좌우 공백 제거\n",
    "    df = df.apply(lambda col: col.str.strip() if col.dtype == \"object\" else col)\n",
    "\n",
    "    # 전화번호, 팩스번호 k-홈페이지, 고용보험관리번호, k-등록일자, k-수정일자, 관리비 업로드, 단지소개기존clob 삭제\n",
    "    df = df.drop(columns=['k-전화번호', 'k-팩스번호', 'k-홈페이지', '고용보험관리번호', 'k-등록일자', 'k-수정일자', '관리비 업로드', '단지소개기존clob'])\n",
    "\n",
    "    # 본번, 부번, 시군구 삭제\n",
    "    df = df.drop(columns=['본번', '부번', '시군구'])\n",
    "\n",
    "    # 계약년월 분해\n",
    "    df['계약(연)'] = df['계약년월'] // 100\n",
    "    df['계약(월)'] = df['계약년월'] % 100\n",
    "    df = df.drop(columns=['계약년월'])\n",
    "\n",
    "    # 계약일 → 계약(일)\n",
    "    df = df.rename(columns={\"계약일\" : \"계약(일)\"})\n",
    "\n",
    "    # 건축년도 → 건물연식\n",
    "    df['건물연식'] = df['건축년도'] - df['계약(연)']\n",
    "\n",
    "    # 해제사유발생일 전처리\n",
    "    df['해제사유발생여부'] = df['해제사유발생일'].notnull().astype(int)\n",
    "\n",
    "    # 세대당_주차대수 특성 생성\n",
    "    df['세대당_주차대수'] = df.apply(\n",
    "    lambda row: row['주차대수'] / row['k-전체세대수'] if pd.notnull(row['주차대수']) and pd.notnull(row['k-전체세대수']) else np.nan,\n",
    "    axis=1)\n",
    "\n",
    "    # 등기신청일자 전처리\n",
    "    df['등기신청여부'] = df['등기신청일자'].notnull().astype(int)\n",
    "\n",
    "    # 불필요 특성 제거\n",
    "    if 'target' in df.columns :\n",
    "        columns_to_keep = [\n",
    "        '전용면적(㎡)', '해제사유발생여부', 'k-전용면적별세대현황(60㎡이하)', '건물연식',\n",
    "        'k-전용면적별세대현황(60㎡~85㎡이하)', '세대당_주차대수', '계약(연)', '계약(월)',\n",
    "        '좌표X', '좌표Y', '아파트명', '등기신청여부', 'k-복도유형', 'k-단지분류(아파트,주상복합등등)', '도로명', 'target'\n",
    "        ]\n",
    "    else :\n",
    "        columns_to_keep = [\n",
    "        '전용면적(㎡)', '해제사유발생여부', 'k-전용면적별세대현황(60㎡이하)', '건물연식',\n",
    "        'k-전용면적별세대현황(60㎡~85㎡이하)', '세대당_주차대수', '계약(연)', '계약(월)',\n",
    "        '좌표X', '좌표Y', '아파트명', '등기신청여부', 'k-복도유형', 'k-단지분류(아파트,주상복합등등)', '도로명'\n",
    "        ]\n",
    "\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    # 특성 이름에서 k- 빼기\n",
    "    df.columns = df.columns.str.replace('k-', '')\n",
    "\n",
    "    # 군집화\n",
    "    ## 카카오 API 호출 함수\n",
    "    def get_coords_kakao(address, api_key):\n",
    "        url = \"https://dapi.kakao.com/v2/local/search/address.json\"\n",
    "        headers = {\"Authorization\": f\"KakaoAK {api_key}\"}\n",
    "        params = {\"query\": address}\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        result = response.json()\n",
    "        \n",
    "        try:\n",
    "            x = float(result['documents'][0]['x'])\n",
    "            y = float(result['documents'][0]['y'])\n",
    "            return x, y\n",
    "        except IndexError:\n",
    "            return None, None\n",
    "\n",
    "    ## 도로명을 기반으로 좌표X와 좌표Y를 받아옴 (결측치에 한해서)\n",
    "    def fill_missing_coords(row):\n",
    "        if pd.isna(row['좌표X']) or pd.isna(row['좌표Y']):\n",
    "            coords = roadname_to_coords.get(row['도로명'])\n",
    "            if coords:\n",
    "                return pd.Series(coords)\n",
    "        return pd.Series([row['좌표X'], row['좌표Y']])\n",
    "    \n",
    "    roadname_to_coords = {}\n",
    "    unique_roads = df.loc[df[['좌표X', '좌표Y']].isnull().any(axis=1), '도로명'].dropna().unique()\n",
    "\n",
    "    api_key = '13b7b7a0b7a853100b56c56f19f6bc24'\n",
    "\n",
    "    for road in tqdm(unique_roads) :\n",
    "        x, y = get_coords_kakao(road, api_key)\n",
    "        if x is not None and y is not None :\n",
    "            roadname_to_coords[road] = (x, y)\n",
    "\n",
    "    df[['좌표X', '좌표Y']] = df.apply(fill_missing_coords, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8441/8441 [09:56<00:00, 14.15it/s]\n"
     ]
    }
   ],
   "source": [
    "df = Entire_Preprocessing(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_high_price_apartment_feature(df, apart_data):\n",
    "    high_price_roads = set(\n",
    "        data['도로명'] for _, data in apart_data[\n",
    "            apart_data['거래금액(만원)'].str.replace(',', '').astype(int) > 200000\n",
    "        ].iterrows()\n",
    "    )\n",
    "    \n",
    "    df_result = df.copy()\n",
    "    df_result['고가아파트'] = df_result['도로명'].isin(high_price_roads).astype(int)\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "df = create_high_price_apartment_feature(df, apart_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22191"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['좌표X'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['좌표X', '좌표Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dst78/anaconda3/envs/Deep/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator KMeans from version 1.3.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/dst78/anaconda3/envs/Deep/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but KMeans was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 군집화\n",
    "kmeans = joblib.load('kmeans_model.pkl')\n",
    "\n",
    "df['cluster'] = kmeans.predict(df[['좌표X', '좌표Y']])\n",
    "df = df.drop(columns=['좌표X', '좌표Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>전용면적(㎡)</th>\n",
       "      <th>해제사유발생여부</th>\n",
       "      <th>전용면적별세대현황(60㎡이하)</th>\n",
       "      <th>건물연식</th>\n",
       "      <th>전용면적별세대현황(60㎡~85㎡이하)</th>\n",
       "      <th>세대당_주차대수</th>\n",
       "      <th>계약(연)</th>\n",
       "      <th>계약(월)</th>\n",
       "      <th>아파트명</th>\n",
       "      <th>등기신청여부</th>\n",
       "      <th>복도유형</th>\n",
       "      <th>단지분류(아파트,주상복합등등)</th>\n",
       "      <th>도로명</th>\n",
       "      <th>target</th>\n",
       "      <th>고가아파트</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.97</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-30</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.97037</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>개포6차우성</td>\n",
       "      <td>1</td>\n",
       "      <td>계단식</td>\n",
       "      <td>아파트</td>\n",
       "      <td>언주로 3</td>\n",
       "      <td>124000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.97</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-30</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.97037</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>개포6차우성</td>\n",
       "      <td>1</td>\n",
       "      <td>계단식</td>\n",
       "      <td>아파트</td>\n",
       "      <td>언주로 3</td>\n",
       "      <td>123500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.98</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-30</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.97037</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>개포6차우성</td>\n",
       "      <td>1</td>\n",
       "      <td>계단식</td>\n",
       "      <td>아파트</td>\n",
       "      <td>언주로 3</td>\n",
       "      <td>91500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   전용면적(㎡)  해제사유발생여부  전용면적별세대현황(60㎡이하)  건물연식  전용면적별세대현황(60㎡~85㎡이하)  세대당_주차대수  \\\n",
       "0    79.97         0              20.0   -30                 250.0   0.97037   \n",
       "1    79.97         0              20.0   -30                 250.0   0.97037   \n",
       "2    54.98         0              20.0   -30                 250.0   0.97037   \n",
       "\n",
       "   계약(연)  계약(월)    아파트명  등기신청여부 복도유형 단지분류(아파트,주상복합등등)    도로명  target  고가아파트  \\\n",
       "0   2017     12  개포6차우성       1  계단식              아파트  언주로 3  124000      1   \n",
       "1   2017     12  개포6차우성       1  계단식              아파트  언주로 3  123500      1   \n",
       "2   2017     12  개포6차우성       1  계단식              아파트  언주로 3   91500      1   \n",
       "\n",
       "   cluster  \n",
       "0        3  \n",
       "1        3  \n",
       "2        3  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_name(name):\n",
    "    return re.sub(r'[^\\uac00-\\ud7a3a-zA-Z0-9_]', '_', name)\n",
    "\n",
    "df.columns = [clean_column_name(col) for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object 타입 특성 변환\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categorical_features:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>전용면적___</th>\n",
       "      <th>해제사유발생여부</th>\n",
       "      <th>전용면적별세대현황_60_이하_</th>\n",
       "      <th>건물연식</th>\n",
       "      <th>전용면적별세대현황_60__85_이하_</th>\n",
       "      <th>세대당_주차대수</th>\n",
       "      <th>계약_연_</th>\n",
       "      <th>계약_월_</th>\n",
       "      <th>아파트명</th>\n",
       "      <th>등기신청여부</th>\n",
       "      <th>복도유형</th>\n",
       "      <th>단지분류_아파트_주상복합등등_</th>\n",
       "      <th>도로명</th>\n",
       "      <th>고가아파트</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331805</th>\n",
       "      <td>74.2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>경남</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>섬밭로 265</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        전용면적___  해제사유발생여부  전용면적별세대현황_60_이하_  건물연식  전용면적별세대현황_60__85_이하_  \\\n",
       "331805     74.2         0               NaN   -31                   NaN   \n",
       "\n",
       "        세대당_주차대수  계약_연_  계약_월_ 아파트명  등기신청여부 복도유형 단지분류_아파트_주상복합등등_      도로명  \\\n",
       "331805       NaN   2020      7   경남       1  NaN              NaN  섬밭로 265   \n",
       "\n",
       "        고가아파트  cluster  \n",
       "331805      0        2  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 특성 스케일링(Data Leakage 방지 적용)\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor()\n",
    "\n",
    "param_space = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 300, 3000, 10)),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.2),\n",
    "    'num_leaves' : scope.int(hp.quniform('num_leaves', 2, 50, 1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 0, 40, 1)),\n",
    "    'min_data_in_leaf' : scope.int(hp.quniform('min_data_in_leaf', 0, 50, 1)),\n",
    "    'feature_fraction_bynode' : hp.uniform('feature_fraction_bynode', 0.001, 1.0),\n",
    "    'bagging_fraction' : hp.uniform('bagging_fraction', 0.001, 1.0),\n",
    "    'bagging_freq' : scope.int(hp.quniform('bagging_freq', 0, 30, 1)),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 0, 10),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 1),\n",
    "    'drop_rate' : hp.uniform('drop_rate', 0, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    lgb_model = lgb.LGBMRegressor(\n",
    "        n_estimators=params['n_estimators'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        num_leaves=params['num_leaves'],\n",
    "        max_depth=params['max_depth'],\n",
    "        min_data_in_leaf=params['min_data_in_leaf'],\n",
    "        feature_fraction_bynode=params['feature_fraction_bynode'],\n",
    "        bagging_fraction=params['bagging_fraction'],\n",
    "        bagging_freq=params['bagging_freq'],\n",
    "        min_child_weight=params['min_child_weight'],\n",
    "        reg_alpha=params['reg_alpha'],\n",
    "        reg_lambda=params['reg_lambda'],\n",
    "        drop_rate=params['drop_rate'],\n",
    "    )\n",
    "    \n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    lgb_pred = lgb_model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, lgb_pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5673379607296918, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5673379607296918\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5673379607296918, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5673379607296918\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5673379607296918, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5673379607296918\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3641821351545945, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3641821351545945\n",
      "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3641821351545945, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3641821351545945\n",
      "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                       \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3641821351545945, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3641821351545945\n",
      "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.22642555972587425, subsample=1.0 will be ignored. Current value: bagging_fraction=0.22642555972587425\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.22642555972587425, subsample=1.0 will be ignored. Current value: bagging_fraction=0.22642555972587425\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                       \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.22642555972587425, subsample=1.0 will be ignored. Current value: bagging_fraction=0.22642555972587425\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.38937040973265724, subsample=1.0 will be ignored. Current value: bagging_fraction=0.38937040973265724\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.38937040973265724, subsample=1.0 will be ignored. Current value: bagging_fraction=0.38937040973265724\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                       \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.38937040973265724, subsample=1.0 will be ignored. Current value: bagging_fraction=0.38937040973265724\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6684378316130698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6684378316130698\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6684378316130698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6684378316130698\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                       \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6684378316130698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6684378316130698\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9455298106833935, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9455298106833935\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9455298106833935, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9455298106833935\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                       \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9455298106833935, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9455298106833935\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.720414413706881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.720414413706881\n",
      "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.720414413706881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.720414413706881\n",
      "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                       \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.720414413706881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.720414413706881\n",
      "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.20499996011078855, subsample=1.0 will be ignored. Current value: bagging_fraction=0.20499996011078855\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.20499996011078855, subsample=1.0 will be ignored. Current value: bagging_fraction=0.20499996011078855\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.20499996011078855, subsample=1.0 will be ignored. Current value: bagging_fraction=0.20499996011078855\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9068242044579977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9068242044579977\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9068242044579977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9068242044579977\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                       \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9068242044579977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9068242044579977\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5889798205847601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5889798205847601\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5889798205847601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5889798205847601\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf     \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5889798205847601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5889798205847601\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.0997291979435485, subsample=1.0 will be ignored. Current value: bagging_fraction=0.0997291979435485\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.0997291979435485, subsample=1.0 will be ignored. Current value: bagging_fraction=0.0997291979435485\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.0997291979435485, subsample=1.0 will be ignored. Current value: bagging_fraction=0.0997291979435485\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44638468698466843, subsample=1.0 will be ignored. Current value: bagging_fraction=0.44638468698466843\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44638468698466843, subsample=1.0 will be ignored. Current value: bagging_fraction=0.44638468698466843\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44638468698466843, subsample=1.0 will be ignored. Current value: bagging_fraction=0.44638468698466843\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5910978341131954, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5910978341131954\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5910978341131954, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5910978341131954\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5910978341131954, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5910978341131954\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9253891004417998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9253891004417998\n",
      "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9253891004417998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9253891004417998\n",
      "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9253891004417998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9253891004417998\n",
      "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8857959565399701, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8857959565399701\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8857959565399701, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8857959565399701\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8857959565399701, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8857959565399701\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4806233991524472, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4806233991524472\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4806233991524472, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4806233991524472\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4806233991524472, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4806233991524472\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.02401596064353861, subsample=1.0 will be ignored. Current value: bagging_fraction=0.02401596064353861\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.02401596064353861, subsample=1.0 will be ignored. Current value: bagging_fraction=0.02401596064353861\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.02401596064353861, subsample=1.0 will be ignored. Current value: bagging_fraction=0.02401596064353861\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.34430692798477636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.34430692798477636\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.34430692798477636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.34430692798477636\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.34430692798477636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.34430692798477636\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2557332163260307, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2557332163260307\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2557332163260307, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2557332163260307\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2557332163260307, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2557332163260307\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.05416165038259762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.05416165038259762\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.05416165038259762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.05416165038259762\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.05416165038259762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.05416165038259762\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.783261353628073, subsample=1.0 will be ignored. Current value: bagging_fraction=0.783261353628073\n",
      "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.783261353628073, subsample=1.0 will be ignored. Current value: bagging_fraction=0.783261353628073\n",
      "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.783261353628073, subsample=1.0 will be ignored. Current value: bagging_fraction=0.783261353628073\n",
      "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7752097426990873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7752097426990873\n",
      "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7752097426990873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7752097426990873\n",
      "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf      \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7752097426990873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7752097426990873\n",
      "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7500164460122742, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7500164460122742\n",
      "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7500164460122742, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7500164460122742\n",
      "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7500164460122742, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7500164460122742\n",
      "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8155555766205038, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8155555766205038\n",
      "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8155555766205038, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8155555766205038\n",
      "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8155555766205038, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8155555766205038\n",
      "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.854324877550307, subsample=1.0 will be ignored. Current value: bagging_fraction=0.854324877550307\n",
      "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.854324877550307, subsample=1.0 will be ignored. Current value: bagging_fraction=0.854324877550307\n",
      "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.854324877550307, subsample=1.0 will be ignored. Current value: bagging_fraction=0.854324877550307\n",
      "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8546484922120094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8546484922120094\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8546484922120094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8546484922120094\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8546484922120094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8546484922120094\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9856527277732143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9856527277732143\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9856527277732143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9856527277732143\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9856527277732143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9856527277732143\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9906973883870043, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9906973883870043\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9906973883870043, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9906973883870043\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9906973883870043, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9906973883870043\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9707236920908655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707236920908655\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9707236920908655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707236920908655\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9707236920908655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707236920908655\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6734095150080148, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6734095150080148\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6734095150080148, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6734095150080148\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6734095150080148, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6734095150080148\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6612002196246201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6612002196246201\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6612002196246201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6612002196246201\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6612002196246201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6612002196246201\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5359771933376163, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5359771933376163\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5359771933376163, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5359771933376163\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5359771933376163, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5359771933376163\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6707387534856604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707387534856604\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6707387534856604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707387534856604\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6707387534856604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707387534856604\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8435858715301534, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8435858715301534\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8435858715301534, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8435858715301534\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8435858715301534, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8435858715301534\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6243543563872233, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6243543563872233\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6243543563872233, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6243543563872233\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6243543563872233, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6243543563872233\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7095338652735785, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7095338652735785\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7095338652735785, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7095338652735785\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7095338652735785, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7095338652735785\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4181909110426252, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4181909110426252\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4181909110426252, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4181909110426252\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4181909110426252, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4181909110426252\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5108766705701173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5108766705701173\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5108766705701173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5108766705701173\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5108766705701173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5108766705701173\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.32602570687185556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.32602570687185556\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.32602570687185556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.32602570687185556\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.32602570687185556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.32602570687185556\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7150339902383819, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7150339902383819\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7150339902383819, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7150339902383819\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7150339902383819, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7150339902383819\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5402068806136822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5402068806136822\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5402068806136822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5402068806136822\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5402068806136822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5402068806136822\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6498219639360725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6498219639360725\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6498219639360725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6498219639360725\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6498219639360725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6498219639360725\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8855837695583129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8855837695583129\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8855837695583129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8855837695583129\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8855837695583129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8855837695583129\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5878132980327971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5878132980327971\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5878132980327971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5878132980327971\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5878132980327971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5878132980327971\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45889692096755397, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45889692096755397\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45889692096755397, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45889692096755397\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45889692096755397, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45889692096755397\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8085482749105621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8085482749105621\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8085482749105621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8085482749105621\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8085482749105621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8085482749105621\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9411265061511105, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9411265061511105\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9411265061511105, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9411265061511105\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9411265061511105, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9411265061511105\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1741628275981364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1741628275981364\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1741628275981364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1741628275981364\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1741628275981364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1741628275981364\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7507441091806134, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7507441091806134\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7507441091806134, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7507441091806134\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7507441091806134, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7507441091806134\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6990438798180894, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6990438798180894\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6990438798180894, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6990438798180894\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636                        \n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6990438798180894, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6990438798180894\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "100%|██████████| 50/50 [13:58<00:00, 16.78s/trial, best loss: 6799.898164350143]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=param_space, algo=tpe.suggest, max_evals=50, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'bagging_fraction': 0.8546484922120094, 'bagging_freq': 0.0, 'drop_rate': 0.8251814575286062, 'feature_fraction_bynode': 0.4696145898729537, 'learning_rate': 0.1670756766194666, 'max_depth': 25.0, 'min_child_weight': 6.336352253884298, 'min_data_in_leaf': 23.0, 'n_estimators': 1580.0, 'num_leaves': 49.0, 'reg_alpha': 0.36887459188045524, 'reg_lambda': 0.22340494687276646}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Hyperparameters: {best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8546484922120094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8546484922120094\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8546484922120094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8546484922120094\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904\n",
      "[LightGBM] [Info] Number of data points in the train set: 877304, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 57544.421636\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(bagging_fraction=0.8546484922120094, bagging_freq=0,\n",
       "              drop_rate=0.8251814575286062,\n",
       "              feature_fraction_bynode=0.4696145898729537,\n",
       "              learning_rate=0.1670756766194666, max_depth=25,\n",
       "              min_child_weight=6.336352253884298, min_data_in_leaf=23,\n",
       "              n_estimators=1580, num_leaves=49, reg_alpha=0.36887459188045524,\n",
       "              reg_lambda=0.22340494687276646)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMRegressor</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(bagging_fraction=0.8546484922120094, bagging_freq=0,\n",
       "              drop_rate=0.8251814575286062,\n",
       "              feature_fraction_bynode=0.4696145898729537,\n",
       "              learning_rate=0.1670756766194666, max_depth=25,\n",
       "              min_child_weight=6.336352253884298, min_data_in_leaf=23,\n",
       "              n_estimators=1580, num_leaves=49, reg_alpha=0.36887459188045524,\n",
       "              reg_lambda=0.22340494687276646)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.8546484922120094, bagging_freq=0,\n",
       "              drop_rate=0.8251814575286062,\n",
       "              feature_fraction_bynode=0.4696145898729537,\n",
       "              learning_rate=0.1670756766194666, max_depth=25,\n",
       "              min_child_weight=6.336352253884298, min_data_in_leaf=23,\n",
       "              n_estimators=1580, num_leaves=49, reg_alpha=0.36887459188045524,\n",
       "              reg_lambda=0.22340494687276646)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = lgb.LGBMRegressor(\n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    learning_rate=best['learning_rate'],\n",
    "    num_leaves=int(best['num_leaves']),\n",
    "    max_depth=int(best['max_depth']),\n",
    "    min_data_in_leaf=int(best['min_data_in_leaf']),\n",
    "    feature_fraction_bynode=best['feature_fraction_bynode'],\n",
    "    bagging_fraction=best['bagging_fraction'],\n",
    "    bagging_freq=int(best['bagging_freq']),\n",
    "    min_child_weight=best['min_child_weight'],\n",
    "    reg_alpha=best['reg_alpha'],\n",
    "    reg_lambda=best['reg_lambda'],\n",
    "    drop_rate=best['drop_rate'],\n",
    ")\n",
    "\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8546484922120094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8546484922120094\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6799.898164350143"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>전용면적___</td>\n",
       "      <td>14707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>계약_연_</td>\n",
       "      <td>13071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>도로명</td>\n",
       "      <td>11118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>아파트명</td>\n",
       "      <td>10960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>건물연식</td>\n",
       "      <td>10821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>계약_월_</td>\n",
       "      <td>8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cluster</td>\n",
       "      <td>2943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>고가아파트</td>\n",
       "      <td>1157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>세대당_주차대수</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>전용면적별세대현황_60_이하_</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>전용면적별세대현황_60__85_이하_</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>해제사유발생여부</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>복도유형</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>단지분류_아파트_주상복합등등_</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>등기신청여부</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature  Importance\n",
       "0                전용면적___       14707\n",
       "6                  계약_연_       13071\n",
       "12                   도로명       11118\n",
       "8                   아파트명       10960\n",
       "3                   건물연식       10821\n",
       "7                  계약_월_        8900\n",
       "14               cluster        2943\n",
       "13                 고가아파트        1157\n",
       "5               세대당_주차대수         683\n",
       "2       전용면적별세대현황_60_이하_         660\n",
       "4   전용면적별세대현황_60__85_이하_         584\n",
       "1               해제사유발생여부         179\n",
       "10                  복도유형          34\n",
       "11      단지분류_아파트_주상복합등등_          23\n",
       "9                 등기신청여부           0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = best_model.feature_importances_\n",
    "\n",
    "# 특성 중요도를 데이터프레임으로 정리\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importance\n",
    "})\n",
    "\n",
    "# 중요도가 높은 순으로 정렬\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2052/2052 [02:33<00:00, 13.34it/s]\n"
     ]
    }
   ],
   "source": [
    "test = Entire_Preprocessing(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = create_high_price_apartment_feature(test, apart_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['좌표X', '좌표Y'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m coord_mask \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m좌표X\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m좌표Y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnotna()\u001b[38;5;241m.\u001b[39mall(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m NaN\n\u001b[1;32m      5\u001b[0m test\u001b[38;5;241m.\u001b[39mloc[coord_mask, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mpredict(test\u001b[38;5;241m.\u001b[39mloc[coord_mask, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m좌표X\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m좌표Y\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "File \u001b[0;32m~/anaconda3/envs/Deep/lib/python3.11/site-packages/pandas/core/frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/Deep/lib/python3.11/site-packages/pandas/core/indexes/base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Deep/lib/python3.11/site-packages/pandas/core/indexes/base.py:6176\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6175\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['좌표X', '좌표Y'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "coord_mask = test[['좌표X', '좌표Y']].notna().all(axis=1)\n",
    "\n",
    "test['cluster'] = 'NaN'\n",
    "\n",
    "test.loc[coord_mask, 'cluster'] = kmeans.predict(test.loc[coord_mask, ['좌표X', '좌표Y']])\n",
    "test = test.drop(columns=['좌표X', '좌표Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>전용면적(㎡)</th>\n",
       "      <th>해제사유발생여부</th>\n",
       "      <th>전용면적별세대현황(60㎡이하)</th>\n",
       "      <th>건물연식</th>\n",
       "      <th>전용면적별세대현황(60㎡~85㎡이하)</th>\n",
       "      <th>세대당_주차대수</th>\n",
       "      <th>계약(연)</th>\n",
       "      <th>계약(월)</th>\n",
       "      <th>아파트명</th>\n",
       "      <th>등기신청여부</th>\n",
       "      <th>복도유형</th>\n",
       "      <th>단지분류(아파트,주상복합등등)</th>\n",
       "      <th>도로명</th>\n",
       "      <th>고가아파트</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.97</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-36</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.97037</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>개포6차우성</td>\n",
       "      <td>1</td>\n",
       "      <td>계단식</td>\n",
       "      <td>아파트</td>\n",
       "      <td>언주로 3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   전용면적(㎡)  해제사유발생여부  전용면적별세대현황(60㎡이하)  건물연식  전용면적별세대현황(60㎡~85㎡이하)  세대당_주차대수  \\\n",
       "0    79.97         0              20.0   -36                 250.0   0.97037   \n",
       "\n",
       "   계약(연)  계약(월)    아파트명  등기신청여부 복도유형 단지분류(아파트,주상복합등등)    도로명  고가아파트 cluster  \n",
       "0   2023      7  개포6차우성       1  계단식              아파트  언주로 3      1       3  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_preprocessing(df) :\n",
    "    df.columns = [clean_column_name(col) for col in df.columns]\n",
    "    categorical_features = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    for col in categorical_features:\n",
    "        df[col] = df[col].astype('category')\n",
    "        \n",
    "    df[numeric_features] = scaler.transform(df[numeric_features])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_preprocessing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>전용면적___</th>\n",
       "      <th>해제사유발생여부</th>\n",
       "      <th>전용면적별세대현황_60_이하_</th>\n",
       "      <th>건물연식</th>\n",
       "      <th>전용면적별세대현황_60__85_이하_</th>\n",
       "      <th>세대당_주차대수</th>\n",
       "      <th>계약_연_</th>\n",
       "      <th>계약_월_</th>\n",
       "      <th>아파트명</th>\n",
       "      <th>등기신청여부</th>\n",
       "      <th>복도유형</th>\n",
       "      <th>단지분류_아파트_주상복합등등_</th>\n",
       "      <th>도로명</th>\n",
       "      <th>고가아파트</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.094108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.388258</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-0.014374</td>\n",
       "      <td>-0.205102</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>개포6차우성</td>\n",
       "      <td>0.0</td>\n",
       "      <td>계단식</td>\n",
       "      <td>아파트</td>\n",
       "      <td>언주로 3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    전용면적___  해제사유발생여부  전용면적별세대현황_60_이하_  건물연식  전용면적별세대현황_60__85_이하_  세대당_주차대수  \\\n",
       "0 -0.094108       0.0         -0.388258  -1.5             -0.014374 -0.205102   \n",
       "\n",
       "      계약_연_     계약_월_    아파트명  등기신청여부 복도유형 단지분류_아파트_주상복합등등_    도로명  고가아파트  \\\n",
       "0  1.142857  0.166667  개포6차우성     0.0  계단식              아파트  언주로 3    1.0   \n",
       "\n",
       "  cluster  \n",
       "0       3  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "train and valid dataset categorical_feature do not match.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Deep/lib/python3.11/site-packages/lightgbm/sklearn.py:961\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m predict_params \u001b[38;5;241m=\u001b[39m _choose_param_value(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m, predict_params, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m    959\u001b[0m predict_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_n_jobs(predict_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 961\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Booster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[union-attr]\u001b[39;49;00m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_params\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Deep/lib/python3.11/site-packages/lightgbm/basic.py:4453\u001b[0m, in \u001b[0;36mBooster.predict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   4451\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4452\u001b[0m         num_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 4453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_has_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_has_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\n\u001b[1;32m   4462\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Deep/lib/python3.11/site-packages/lightgbm/basic.py:1116\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[0m\n\u001b[1;32m   1107\u001b[0m     _safe_call(\n\u001b[1;32m   1108\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterValidateFeatureNames(\n\u001b[1;32m   1109\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         )\n\u001b[1;32m   1113\u001b[0m     )\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[0;32m-> 1116\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_data_from_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpandas_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas_categorical\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1123\u001b[0m predict_type \u001b[38;5;241m=\u001b[39m _C_API_PREDICT_NORMAL\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raw_score:\n",
      "File \u001b[0;32m~/anaconda3/envs/Deep/lib/python3.11/site-packages/lightgbm/basic.py:808\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cat_cols) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(pandas_categorical):\n\u001b[0;32m--> 808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain and valid dataset categorical_feature do not match.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col, category \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(cat_cols, pandas_categorical):\n\u001b[1;32m    810\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(data[col]\u001b[38;5;241m.\u001b[39mcat\u001b[38;5;241m.\u001b[39mcategories) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m(category):\n",
      "\u001b[0;31mValueError\u001b[0m: train and valid dataset categorical_feature do not match."
     ]
    }
   ],
   "source": [
    "pred = best_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0  179048"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>299319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>249677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0  190039\n",
       "1  252180\n",
       "2  299319\n",
       "3  249677\n",
       "4  195089"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
